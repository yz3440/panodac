{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"panodac # Metric depth estimation for any camera. Perspective, fisheye, 360\u00b0 panorama. Based on Depth Any Camera (CVPR 2025). Installation # pip install panodac Or install from source: pip install \"panodac @ git+https://github.com/yz3440/panodac.git\" Quick Start # import panodac # Predict depth from any image depth = panodac . predict ( \"photo.jpg\" ) # depth is a numpy array (H, W) with metric depth in meters # Use a specific model depth = panodac . predict ( \"panorama.jpg\" , model = \"outdoor-swinl\" ) # List available models print ( panodac . list_models ()) # ['outdoor-resnet101', 'outdoor-swinl', 'indoor-resnet101', 'indoor-swinl'] Models # Model Use Case Speed Quality outdoor-resnet101 Outdoor Fast Good outdoor-swinl Outdoor Slow Best indoor-resnet101 Indoor Fast Good indoor-swinl Indoor Slow Best Models auto-download from HuggingFace on first use (~500MB each). Device Selection # panodac automatically uses the best available device: Apple Silicon (MPS) \u2014 Used by default on M1/M2/M3 Macs CUDA \u2014 Used when NVIDIA GPU is available CPU \u2014 Fallback when no GPU is available # Check current device print ( panodac . get_device ()) # 'mps', 'cuda', or 'cpu' # Force specific device depth = panodac . predict ( \"image.jpg\" , device = \"cpu\" ) Input Formats # The predict() function accepts multiple input types: import panodac from PIL import Image import numpy as np # File path (string or Path) depth = panodac . predict ( \"photo.jpg\" ) # PIL Image img = Image . open ( \"photo.jpg\" ) depth = panodac . predict ( img ) # NumPy array (H, W, 3) RGB img_np = np . array ( Image . open ( \"photo.jpg\" )) depth = panodac . predict ( img_np ) Panorama Detection # 360\u00b0 equirectangular panoramas (2:1 aspect ratio) are automatically detected and processed with appropriate spherical coordinates. # Panoramas are auto-detected depth = panodac . predict ( \"panorama_360.jpg\" ) Panorama Seam Correction # ERP panoramas wrap horizontally, but CNNs can produce a seam at the left/right boundary. By default, panodac applies a Poisson-based seam correction on detected panoramas. # Default: seam correction enabled for panoramas depth = panodac . predict ( \"panorama_360.jpg\" ) # Disable seam correction depth_raw = panodac . predict ( \"panorama_360.jpg\" , fix_panorama_seam = False ) Next # Examples - Working scripts API Reference - Full documentation","title":"Home"},{"location":"#panodac","text":"Metric depth estimation for any camera. Perspective, fisheye, 360\u00b0 panorama. Based on Depth Any Camera (CVPR 2025).","title":"panodac"},{"location":"#installation","text":"pip install panodac Or install from source: pip install \"panodac @ git+https://github.com/yz3440/panodac.git\"","title":"Installation"},{"location":"#quick-start","text":"import panodac # Predict depth from any image depth = panodac . predict ( \"photo.jpg\" ) # depth is a numpy array (H, W) with metric depth in meters # Use a specific model depth = panodac . predict ( \"panorama.jpg\" , model = \"outdoor-swinl\" ) # List available models print ( panodac . list_models ()) # ['outdoor-resnet101', 'outdoor-swinl', 'indoor-resnet101', 'indoor-swinl']","title":"Quick Start"},{"location":"#models","text":"Model Use Case Speed Quality outdoor-resnet101 Outdoor Fast Good outdoor-swinl Outdoor Slow Best indoor-resnet101 Indoor Fast Good indoor-swinl Indoor Slow Best Models auto-download from HuggingFace on first use (~500MB each).","title":"Models"},{"location":"#device-selection","text":"panodac automatically uses the best available device: Apple Silicon (MPS) \u2014 Used by default on M1/M2/M3 Macs CUDA \u2014 Used when NVIDIA GPU is available CPU \u2014 Fallback when no GPU is available # Check current device print ( panodac . get_device ()) # 'mps', 'cuda', or 'cpu' # Force specific device depth = panodac . predict ( \"image.jpg\" , device = \"cpu\" )","title":"Device Selection"},{"location":"#input-formats","text":"The predict() function accepts multiple input types: import panodac from PIL import Image import numpy as np # File path (string or Path) depth = panodac . predict ( \"photo.jpg\" ) # PIL Image img = Image . open ( \"photo.jpg\" ) depth = panodac . predict ( img ) # NumPy array (H, W, 3) RGB img_np = np . array ( Image . open ( \"photo.jpg\" )) depth = panodac . predict ( img_np )","title":"Input Formats"},{"location":"#panorama-detection","text":"360\u00b0 equirectangular panoramas (2:1 aspect ratio) are automatically detected and processed with appropriate spherical coordinates. # Panoramas are auto-detected depth = panodac . predict ( \"panorama_360.jpg\" )","title":"Panorama Detection"},{"location":"#panorama-seam-correction","text":"ERP panoramas wrap horizontally, but CNNs can produce a seam at the left/right boundary. By default, panodac applies a Poisson-based seam correction on detected panoramas. # Default: seam correction enabled for panoramas depth = panodac . predict ( \"panorama_360.jpg\" ) # Disable seam correction depth_raw = panodac . predict ( \"panorama_360.jpg\" , fix_panorama_seam = False )","title":"Panorama Seam Correction"},{"location":"#next","text":"Examples - Working scripts API Reference - Full documentation","title":"Next"},{"location":"examples/","text":"Examples # Working scripts in examples/ . basic_depth.py # Basic depth prediction and visualization. #!/usr/bin/env python3 \"\"\" Basic depth prediction example. This demonstrates the simplest usage of panodac: predicting depth from a single image. \"\"\" import panodac import numpy as np from PIL import Image import matplotlib.pyplot as plt def main (): # Predict depth - it's this simple! depth = panodac . predict ( \"path/to/your/image.jpg\" ) # depth is a numpy array (H, W) with metric depth in meters print ( f \"Depth shape: { depth . shape } \" ) print ( f \"Depth range: { depth . min () : .2f } m - { depth . max () : .2f } m\" ) # Visualize the depth map plt . figure ( figsize = ( 12 , 5 )) plt . subplot ( 1 , 2 , 1 ) plt . title ( \"Input Image\" ) plt . imshow ( Image . open ( \"path/to/your/image.jpg\" )) plt . axis ( \"off\" ) plt . subplot ( 1 , 2 , 2 ) plt . title ( \"Predicted Depth\" ) plt . imshow ( depth , cmap = \"turbo\" ) plt . colorbar ( label = \"Depth (m)\" ) plt . axis ( \"off\" ) plt . tight_layout () plt . savefig ( \"depth_result.jpg\" ) print ( \"Saved visualization to depth_result.jpg\" ) def example_with_options (): \"\"\"Example showing all available options.\"\"\" # List available models print ( \"Available models:\" , panodac . list_models ()) # Output: ['outdoor-resnet101', 'outdoor-swinl', 'indoor-resnet101', 'indoor-swinl'] # Check current device print ( \"Using device:\" , panodac . get_device ()) # Output: cpu, cuda, or mps (depending on your system) # Predict with a specific model depth = panodac . predict ( \"photo.jpg\" , model = \"outdoor-swinl\" , # Higher quality, slower device = \"mps\" , # Force specific device ) # The predict function accepts multiple input types: # 1. File path (string or Path) depth = panodac . predict ( \"photo.jpg\" ) # 2. PIL Image from PIL import Image img = Image . open ( \"photo.jpg\" ) depth = panodac . predict ( img ) # 3. NumPy array (H, W, 3) RGB img_np = np . array ( Image . open ( \"photo.jpg\" )) depth = panodac . predict ( img_np ) if __name__ == \"__main__\" : main () panorama_depth.py # 360\u00b0 panorama depth prediction with point cloud export. #!/usr/bin/env python3 \"\"\" Panorama depth prediction with point cloud export. This example shows how to process 360\u00b0 equirectangular panoramas and export the result as a 3D point cloud. \"\"\" import numpy as np import panodac from PIL import Image def main (): # Path to your panorama image (should have 2:1 aspect ratio) pano_path = \"../assets/test-pano.jpg\" # Predict depth print ( \"Predicting depth...\" ) depth = panodac . predict ( pano_path , model = \"outdoor-resnet101\" ) print ( f \"Depth shape: { depth . shape } \" ) print ( f \"Depth range: { depth . min () : .2f } m - { depth . max () : .2f } m\" ) # Save depth visualization save_depth_visualization ( depth , \"panorama_depth.jpg\" ) # Export as point cloud print ( \"Generating point cloud...\" ) pano_img = np . array ( Image . open ( pano_path )) points , colors = erp_to_pointcloud ( pano_img , depth ) save_ply ( \"panorama_pointcloud.ply\" , points , colors ) print ( f \"Saved point cloud with { len ( points ) } points\" ) def save_depth_visualization ( depth : np . ndarray , output_path : str ): \"\"\"Save a colorized depth visualization.\"\"\" import cv2 # Normalize depth to 0-255 for visualization depth_norm = ( depth - depth . min ()) / ( depth . max () - depth . min ()) depth_vis = ( depth_norm * 255 ) . astype ( np . uint8 ) # Apply colormap depth_colored = cv2 . applyColorMap ( depth_vis , cv2 . COLORMAP_TURBO ) depth_colored = cv2 . cvtColor ( depth_colored , cv2 . COLOR_BGR2RGB ) Image . fromarray ( depth_colored ) . save ( output_path ) print ( f \"Saved depth visualization to { output_path } \" ) def erp_to_pointcloud ( image : np . ndarray , depth : np . ndarray , max_points : int = 500000 , min_depth : float = 0.1 , max_depth : float = 100.0 , ) -> tuple [ np . ndarray , np . ndarray ]: \"\"\"Convert equirectangular panorama with depth to 3D point cloud. Args: image: RGB image (H, W, 3) depth: Depth map (H, W) in meters max_points: Maximum number of points to generate min_depth: Minimum depth threshold in meters max_depth: Maximum depth threshold in meters Returns: points: (N, 3) xyz coordinates colors: (N, 3) RGB colors (0-255) \"\"\" H , W = depth . shape # Create coordinate grids u = np . linspace ( 0 , 1 , W , dtype = np . float32 ) v = np . linspace ( 0 , 1 , H , dtype = np . float32 ) u , v = np . meshgrid ( u , v ) # Convert to spherical coordinates # u: 0->1 maps to longitude -\u03c0->\u03c0 # v: 0->1 maps to latitude \u03c0/2->-\u03c0/2 longitude = ( u - 0.5 ) * 2 * np . pi latitude = ( 0.5 - v ) * np . pi # Convert to Cartesian coordinates (Y-up convention) # x: right, y: up, z: forward x = depth * np . cos ( latitude ) * np . sin ( longitude ) y = depth * np . sin ( latitude ) z = depth * np . cos ( latitude ) * np . cos ( longitude ) # Flatten all arrays points = np . stack ([ x . ravel (), y . ravel (), z . ravel ()], axis = 1 ) colors = image . reshape ( - 1 , 3 ) depth_flat = depth . ravel () # Filter by actual depth (radial distance), not Cartesian z-coordinate # This is critical for 360\u00b0 panoramas where z can be negative (behind viewer) valid = ( depth_flat > min_depth ) & ( depth_flat < max_depth ) points = points [ valid ] colors = colors [ valid ] # Subsample if too many points (after filtering to preserve valid point ratio) if len ( points ) > max_points : idx = np . random . choice ( len ( points ), max_points , replace = False ) points = points [ idx ] colors = colors [ idx ] return points , colors def save_ply ( filename : str , points : np . ndarray , colors : np . ndarray ): \"\"\"Save point cloud to PLY file.\"\"\" with open ( filename , \"w\" ) as f : f . write ( \"ply \\n \" ) f . write ( \"format ascii 1.0 \\n \" ) f . write ( f \"element vertex { len ( points ) } \\n \" ) f . write ( \"property float x \\n \" ) f . write ( \"property float y \\n \" ) f . write ( \"property float z \\n \" ) f . write ( \"property uchar red \\n \" ) f . write ( \"property uchar green \\n \" ) f . write ( \"property uchar blue \\n \" ) f . write ( \"end_header \\n \" ) for ( x , y , z ), ( r , g , b ) in zip ( points , colors ): f . write ( f \" { x : .4f } { y : .4f } { z : .4f } { int ( r ) } { int ( g ) } { int ( b ) } \\n \" ) if __name__ == \"__main__\" : main () panorama_depth_compare_blending.py # Compare ERP panorama depth output with and without Poisson seam blending. #!/usr/bin/env python3 \"\"\" Panorama depth prediction: compare seam correction on/off. This example runs the model once (without seam correction), then applies the Poisson seam blender as a post-process to produce a blended result. It saves: - panorama_depth_no_blend.jpg - panorama_depth_blend.jpg and prints simple seam metrics. \"\"\" import numpy as np import panodac from PIL import Image def main (): # Path to your panorama image (should have 2:1 aspect ratio) pano_path = \"../assets/test-pano.jpg\" print ( \"Predicting raw depth (no blending)...\" ) depth_raw = panodac . predict ( pano_path , model = \"outdoor-resnet101\" , fix_panorama_seam = False , ) print ( f \"Raw depth shape: { depth_raw . shape } \" ) print ( f \"Raw depth range: { depth_raw . min () : .2f } m - { depth_raw . max () : .2f } m\" ) print ( \"Applying Poisson seam blending...\" ) from panodac.seam_blending import fix_panorama_seam , validate_seam_quality H , W = depth_raw . shape blend_width = max ( 8 , W // 32 ) depth_blend = fix_panorama_seam ( depth_raw , blend_width = blend_width ) metrics = validate_seam_quality ( depth_raw , depth_blend ) print ( \"Seam discontinuity (mean |col0-colLast|): \" f \" { metrics [ 'seam_diff_before' ] : .4f } -> { metrics [ 'seam_diff_after' ] : .4f } \" f \"( { metrics [ 'improvement_pct' ] : .1f } %)\" ) save_depth_visualization ( depth_raw , \"panorama_depth_no_blend.jpg\" ) save_depth_visualization ( depth_blend , \"panorama_depth_blend.jpg\" ) def save_depth_visualization ( depth : np . ndarray , output_path : str ): \"\"\"Save a colorized depth visualization.\"\"\" import cv2 depth = depth . astype ( np . float32 , copy = False ) dmin , dmax = float ( depth . min ()), float ( depth . max ()) denom = max ( 1e-6 , dmax - dmin ) # Normalize depth to 0-255 for visualization depth_norm = ( depth - dmin ) / denom depth_vis = ( depth_norm * 255 ) . astype ( np . uint8 ) # Apply colormap depth_colored = cv2 . applyColorMap ( depth_vis , cv2 . COLORMAP_TURBO ) depth_colored = cv2 . cvtColor ( depth_colored , cv2 . COLOR_BGR2RGB ) Image . fromarray ( depth_colored ) . save ( output_path ) print ( f \"Saved depth visualization to { output_path } \" ) if __name__ == \"__main__\" : main () batch_inference.py # Batch process multiple images from the command line. #!/usr/bin/env python3 \"\"\" Batch processing example. Process multiple images from a directory and save depth maps. \"\"\" import argparse from pathlib import Path import cv2 import numpy as np from PIL import Image from tqdm import tqdm import panodac def main (): parser = argparse . ArgumentParser ( description = \"Batch depth prediction\" ) parser . add_argument ( \"input_dir\" , type = str , help = \"Directory with input images\" ) parser . add_argument ( \"output_dir\" , type = str , help = \"Directory for output depth maps\" ) parser . add_argument ( \"--model\" , type = str , default = \"outdoor-resnet101\" , choices = panodac . list_models (), help = \"Model to use\" ) parser . add_argument ( \"--format\" , type = str , default = \"png\" , choices = [ \"png\" , \"npy\" , \"exr\" ], help = \"Output format for depth maps\" ) args = parser . parse_args () # Create output directory input_dir = Path ( args . input_dir ) output_dir = Path ( args . output_dir ) output_dir . mkdir ( parents = True , exist_ok = True ) # Find all images extensions = { \".jpg\" , \".jpeg\" , \".png\" , \".webp\" , \".bmp\" } image_files = [ f for f in input_dir . iterdir () if f . suffix . lower () in extensions ] if not image_files : print ( f \"No images found in { input_dir } \" ) return print ( f \"Found { len ( image_files ) } images\" ) print ( f \"Using model: { args . model } \" ) print ( f \"Using device: { panodac . get_device () } \" ) # Process images for img_path in tqdm ( image_files , desc = \"Processing\" ): try : # Predict depth depth = panodac . predict ( str ( img_path ), model = args . model ) # Save output output_name = img_path . stem + \"_depth\" if args . format == \"png\" : # Save as 16-bit PNG (depth in mm) depth_mm = ( depth * 1000 ) . astype ( np . uint16 ) output_path = output_dir / f \" { output_name } .png\" cv2 . imwrite ( str ( output_path ), depth_mm ) elif args . format == \"npy\" : # Save as numpy array (original float values in meters) output_path = output_dir / f \" { output_name } .npy\" np . save ( output_path , depth ) elif args . format == \"exr\" : # Save as OpenEXR (requires opencv-python-headless[contrib]) output_path = output_dir / f \" { output_name } .exr\" cv2 . imwrite ( str ( output_path ), depth . astype ( np . float32 )) # Also save a visualization save_visualization ( depth , output_dir / f \" { output_name } _vis.jpg\" ) except Exception as e : print ( f \" \\n Error processing { img_path . name } : { e } \" ) print ( f \" \\n Results saved to { output_dir } \" ) def save_visualization ( depth : np . ndarray , output_path : Path ): \"\"\"Save a colorized depth visualization.\"\"\" # Normalize depth depth_norm = ( depth - depth . min ()) / ( depth . max () - depth . min () + 1e-8 ) depth_vis = ( depth_norm * 255 ) . astype ( np . uint8 ) # Apply colormap depth_colored = cv2 . applyColorMap ( depth_vis , cv2 . COLORMAP_TURBO ) cv2 . imwrite ( str ( output_path ), depth_colored ) if __name__ == \"__main__\" : main ()","title":"Examples"},{"location":"examples/#examples","text":"Working scripts in examples/ .","title":"Examples"},{"location":"examples/#basic_depthpy","text":"Basic depth prediction and visualization. #!/usr/bin/env python3 \"\"\" Basic depth prediction example. This demonstrates the simplest usage of panodac: predicting depth from a single image. \"\"\" import panodac import numpy as np from PIL import Image import matplotlib.pyplot as plt def main (): # Predict depth - it's this simple! depth = panodac . predict ( \"path/to/your/image.jpg\" ) # depth is a numpy array (H, W) with metric depth in meters print ( f \"Depth shape: { depth . shape } \" ) print ( f \"Depth range: { depth . min () : .2f } m - { depth . max () : .2f } m\" ) # Visualize the depth map plt . figure ( figsize = ( 12 , 5 )) plt . subplot ( 1 , 2 , 1 ) plt . title ( \"Input Image\" ) plt . imshow ( Image . open ( \"path/to/your/image.jpg\" )) plt . axis ( \"off\" ) plt . subplot ( 1 , 2 , 2 ) plt . title ( \"Predicted Depth\" ) plt . imshow ( depth , cmap = \"turbo\" ) plt . colorbar ( label = \"Depth (m)\" ) plt . axis ( \"off\" ) plt . tight_layout () plt . savefig ( \"depth_result.jpg\" ) print ( \"Saved visualization to depth_result.jpg\" ) def example_with_options (): \"\"\"Example showing all available options.\"\"\" # List available models print ( \"Available models:\" , panodac . list_models ()) # Output: ['outdoor-resnet101', 'outdoor-swinl', 'indoor-resnet101', 'indoor-swinl'] # Check current device print ( \"Using device:\" , panodac . get_device ()) # Output: cpu, cuda, or mps (depending on your system) # Predict with a specific model depth = panodac . predict ( \"photo.jpg\" , model = \"outdoor-swinl\" , # Higher quality, slower device = \"mps\" , # Force specific device ) # The predict function accepts multiple input types: # 1. File path (string or Path) depth = panodac . predict ( \"photo.jpg\" ) # 2. PIL Image from PIL import Image img = Image . open ( \"photo.jpg\" ) depth = panodac . predict ( img ) # 3. NumPy array (H, W, 3) RGB img_np = np . array ( Image . open ( \"photo.jpg\" )) depth = panodac . predict ( img_np ) if __name__ == \"__main__\" : main ()","title":"basic_depth.py"},{"location":"examples/#panorama_depthpy","text":"360\u00b0 panorama depth prediction with point cloud export. #!/usr/bin/env python3 \"\"\" Panorama depth prediction with point cloud export. This example shows how to process 360\u00b0 equirectangular panoramas and export the result as a 3D point cloud. \"\"\" import numpy as np import panodac from PIL import Image def main (): # Path to your panorama image (should have 2:1 aspect ratio) pano_path = \"../assets/test-pano.jpg\" # Predict depth print ( \"Predicting depth...\" ) depth = panodac . predict ( pano_path , model = \"outdoor-resnet101\" ) print ( f \"Depth shape: { depth . shape } \" ) print ( f \"Depth range: { depth . min () : .2f } m - { depth . max () : .2f } m\" ) # Save depth visualization save_depth_visualization ( depth , \"panorama_depth.jpg\" ) # Export as point cloud print ( \"Generating point cloud...\" ) pano_img = np . array ( Image . open ( pano_path )) points , colors = erp_to_pointcloud ( pano_img , depth ) save_ply ( \"panorama_pointcloud.ply\" , points , colors ) print ( f \"Saved point cloud with { len ( points ) } points\" ) def save_depth_visualization ( depth : np . ndarray , output_path : str ): \"\"\"Save a colorized depth visualization.\"\"\" import cv2 # Normalize depth to 0-255 for visualization depth_norm = ( depth - depth . min ()) / ( depth . max () - depth . min ()) depth_vis = ( depth_norm * 255 ) . astype ( np . uint8 ) # Apply colormap depth_colored = cv2 . applyColorMap ( depth_vis , cv2 . COLORMAP_TURBO ) depth_colored = cv2 . cvtColor ( depth_colored , cv2 . COLOR_BGR2RGB ) Image . fromarray ( depth_colored ) . save ( output_path ) print ( f \"Saved depth visualization to { output_path } \" ) def erp_to_pointcloud ( image : np . ndarray , depth : np . ndarray , max_points : int = 500000 , min_depth : float = 0.1 , max_depth : float = 100.0 , ) -> tuple [ np . ndarray , np . ndarray ]: \"\"\"Convert equirectangular panorama with depth to 3D point cloud. Args: image: RGB image (H, W, 3) depth: Depth map (H, W) in meters max_points: Maximum number of points to generate min_depth: Minimum depth threshold in meters max_depth: Maximum depth threshold in meters Returns: points: (N, 3) xyz coordinates colors: (N, 3) RGB colors (0-255) \"\"\" H , W = depth . shape # Create coordinate grids u = np . linspace ( 0 , 1 , W , dtype = np . float32 ) v = np . linspace ( 0 , 1 , H , dtype = np . float32 ) u , v = np . meshgrid ( u , v ) # Convert to spherical coordinates # u: 0->1 maps to longitude -\u03c0->\u03c0 # v: 0->1 maps to latitude \u03c0/2->-\u03c0/2 longitude = ( u - 0.5 ) * 2 * np . pi latitude = ( 0.5 - v ) * np . pi # Convert to Cartesian coordinates (Y-up convention) # x: right, y: up, z: forward x = depth * np . cos ( latitude ) * np . sin ( longitude ) y = depth * np . sin ( latitude ) z = depth * np . cos ( latitude ) * np . cos ( longitude ) # Flatten all arrays points = np . stack ([ x . ravel (), y . ravel (), z . ravel ()], axis = 1 ) colors = image . reshape ( - 1 , 3 ) depth_flat = depth . ravel () # Filter by actual depth (radial distance), not Cartesian z-coordinate # This is critical for 360\u00b0 panoramas where z can be negative (behind viewer) valid = ( depth_flat > min_depth ) & ( depth_flat < max_depth ) points = points [ valid ] colors = colors [ valid ] # Subsample if too many points (after filtering to preserve valid point ratio) if len ( points ) > max_points : idx = np . random . choice ( len ( points ), max_points , replace = False ) points = points [ idx ] colors = colors [ idx ] return points , colors def save_ply ( filename : str , points : np . ndarray , colors : np . ndarray ): \"\"\"Save point cloud to PLY file.\"\"\" with open ( filename , \"w\" ) as f : f . write ( \"ply \\n \" ) f . write ( \"format ascii 1.0 \\n \" ) f . write ( f \"element vertex { len ( points ) } \\n \" ) f . write ( \"property float x \\n \" ) f . write ( \"property float y \\n \" ) f . write ( \"property float z \\n \" ) f . write ( \"property uchar red \\n \" ) f . write ( \"property uchar green \\n \" ) f . write ( \"property uchar blue \\n \" ) f . write ( \"end_header \\n \" ) for ( x , y , z ), ( r , g , b ) in zip ( points , colors ): f . write ( f \" { x : .4f } { y : .4f } { z : .4f } { int ( r ) } { int ( g ) } { int ( b ) } \\n \" ) if __name__ == \"__main__\" : main ()","title":"panorama_depth.py"},{"location":"examples/#panorama_depth_compare_blendingpy","text":"Compare ERP panorama depth output with and without Poisson seam blending. #!/usr/bin/env python3 \"\"\" Panorama depth prediction: compare seam correction on/off. This example runs the model once (without seam correction), then applies the Poisson seam blender as a post-process to produce a blended result. It saves: - panorama_depth_no_blend.jpg - panorama_depth_blend.jpg and prints simple seam metrics. \"\"\" import numpy as np import panodac from PIL import Image def main (): # Path to your panorama image (should have 2:1 aspect ratio) pano_path = \"../assets/test-pano.jpg\" print ( \"Predicting raw depth (no blending)...\" ) depth_raw = panodac . predict ( pano_path , model = \"outdoor-resnet101\" , fix_panorama_seam = False , ) print ( f \"Raw depth shape: { depth_raw . shape } \" ) print ( f \"Raw depth range: { depth_raw . min () : .2f } m - { depth_raw . max () : .2f } m\" ) print ( \"Applying Poisson seam blending...\" ) from panodac.seam_blending import fix_panorama_seam , validate_seam_quality H , W = depth_raw . shape blend_width = max ( 8 , W // 32 ) depth_blend = fix_panorama_seam ( depth_raw , blend_width = blend_width ) metrics = validate_seam_quality ( depth_raw , depth_blend ) print ( \"Seam discontinuity (mean |col0-colLast|): \" f \" { metrics [ 'seam_diff_before' ] : .4f } -> { metrics [ 'seam_diff_after' ] : .4f } \" f \"( { metrics [ 'improvement_pct' ] : .1f } %)\" ) save_depth_visualization ( depth_raw , \"panorama_depth_no_blend.jpg\" ) save_depth_visualization ( depth_blend , \"panorama_depth_blend.jpg\" ) def save_depth_visualization ( depth : np . ndarray , output_path : str ): \"\"\"Save a colorized depth visualization.\"\"\" import cv2 depth = depth . astype ( np . float32 , copy = False ) dmin , dmax = float ( depth . min ()), float ( depth . max ()) denom = max ( 1e-6 , dmax - dmin ) # Normalize depth to 0-255 for visualization depth_norm = ( depth - dmin ) / denom depth_vis = ( depth_norm * 255 ) . astype ( np . uint8 ) # Apply colormap depth_colored = cv2 . applyColorMap ( depth_vis , cv2 . COLORMAP_TURBO ) depth_colored = cv2 . cvtColor ( depth_colored , cv2 . COLOR_BGR2RGB ) Image . fromarray ( depth_colored ) . save ( output_path ) print ( f \"Saved depth visualization to { output_path } \" ) if __name__ == \"__main__\" : main ()","title":"panorama_depth_compare_blending.py"},{"location":"examples/#batch_inferencepy","text":"Batch process multiple images from the command line. #!/usr/bin/env python3 \"\"\" Batch processing example. Process multiple images from a directory and save depth maps. \"\"\" import argparse from pathlib import Path import cv2 import numpy as np from PIL import Image from tqdm import tqdm import panodac def main (): parser = argparse . ArgumentParser ( description = \"Batch depth prediction\" ) parser . add_argument ( \"input_dir\" , type = str , help = \"Directory with input images\" ) parser . add_argument ( \"output_dir\" , type = str , help = \"Directory for output depth maps\" ) parser . add_argument ( \"--model\" , type = str , default = \"outdoor-resnet101\" , choices = panodac . list_models (), help = \"Model to use\" ) parser . add_argument ( \"--format\" , type = str , default = \"png\" , choices = [ \"png\" , \"npy\" , \"exr\" ], help = \"Output format for depth maps\" ) args = parser . parse_args () # Create output directory input_dir = Path ( args . input_dir ) output_dir = Path ( args . output_dir ) output_dir . mkdir ( parents = True , exist_ok = True ) # Find all images extensions = { \".jpg\" , \".jpeg\" , \".png\" , \".webp\" , \".bmp\" } image_files = [ f for f in input_dir . iterdir () if f . suffix . lower () in extensions ] if not image_files : print ( f \"No images found in { input_dir } \" ) return print ( f \"Found { len ( image_files ) } images\" ) print ( f \"Using model: { args . model } \" ) print ( f \"Using device: { panodac . get_device () } \" ) # Process images for img_path in tqdm ( image_files , desc = \"Processing\" ): try : # Predict depth depth = panodac . predict ( str ( img_path ), model = args . model ) # Save output output_name = img_path . stem + \"_depth\" if args . format == \"png\" : # Save as 16-bit PNG (depth in mm) depth_mm = ( depth * 1000 ) . astype ( np . uint16 ) output_path = output_dir / f \" { output_name } .png\" cv2 . imwrite ( str ( output_path ), depth_mm ) elif args . format == \"npy\" : # Save as numpy array (original float values in meters) output_path = output_dir / f \" { output_name } .npy\" np . save ( output_path , depth ) elif args . format == \"exr\" : # Save as OpenEXR (requires opencv-python-headless[contrib]) output_path = output_dir / f \" { output_name } .exr\" cv2 . imwrite ( str ( output_path ), depth . astype ( np . float32 )) # Also save a visualization save_visualization ( depth , output_dir / f \" { output_name } _vis.jpg\" ) except Exception as e : print ( f \" \\n Error processing { img_path . name } : { e } \" ) print ( f \" \\n Results saved to { output_dir } \" ) def save_visualization ( depth : np . ndarray , output_path : Path ): \"\"\"Save a colorized depth visualization.\"\"\" # Normalize depth depth_norm = ( depth - depth . min ()) / ( depth . max () - depth . min () + 1e-8 ) depth_vis = ( depth_norm * 255 ) . astype ( np . uint8 ) # Apply colormap depth_colored = cv2 . applyColorMap ( depth_vis , cv2 . COLORMAP_TURBO ) cv2 . imwrite ( str ( output_path ), depth_colored ) if __name__ == \"__main__\" : main ()","title":"batch_inference.py"},{"location":"api/","text":"API Reference # Top-Level API # The main entry points are in the panodac module. predict # predict ( image : Union [ str , Path , ndarray , Image ], model : str = 'outdoor-resnet101' , device : Union [ str , None ] = None , fix_panorama_seam : bool = True ) -> np . ndarray Predict metric depth from any camera image. Supports perspective, fisheye, and 360\u00b0 panorama images. Models are automatically downloaded from HuggingFace on first use. Parameters: Name Type Description Default image Union [ str , Path , ndarray , Image ] Input image. Can be: - Path to image file (str or Path) - numpy array (H, W, 3) in RGB format, values 0-255 - PIL Image required model str Model to use. One of: - 'outdoor-resnet101' (default): Fast outdoor model - 'outdoor-swinl': High-quality outdoor model - 'indoor-resnet101': Fast indoor model - 'indoor-swinl': High-quality indoor model 'outdoor-resnet101' device Union [ str , None] Device to use ('cuda', 'mps', 'cpu', or None for auto-detect) None fix_panorama_seam bool If True (default), apply Poisson blending to correct left-right seam artifacts in ERP panorama depth outputs. True Returns: Type Description ndarray Depth map as numpy array (H, W) with metric depth in meters. Example import panodac depth = panodac.predict(\"photo.jpg\") depth = panodac.predict(\"panorama.jpg\", model=\"outdoor-swinl\") Source code in src/panodac/__init__.py 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 def predict ( image : Union [ str , Path , np . ndarray , Image . Image ], model : str = \"outdoor-resnet101\" , device : Union [ str , None ] = None , fix_panorama_seam : bool = True , ) -> np . ndarray : \"\"\"Predict metric depth from any camera image. Supports perspective, fisheye, and 360\u00b0 panorama images. Models are automatically downloaded from HuggingFace on first use. Args: image: Input image. Can be: - Path to image file (str or Path) - numpy array (H, W, 3) in RGB format, values 0-255 - PIL Image model: Model to use. One of: - 'outdoor-resnet101' (default): Fast outdoor model - 'outdoor-swinl': High-quality outdoor model - 'indoor-resnet101': Fast indoor model - 'indoor-swinl': High-quality indoor model device: Device to use ('cuda', 'mps', 'cpu', or None for auto-detect) fix_panorama_seam: If True (default), apply Poisson blending to correct left-right seam artifacts in ERP panorama depth outputs. Returns: Depth map as numpy array (H, W) with metric depth in meters. Example: >>> import panodac >>> depth = panodac.predict(\"photo.jpg\") >>> depth = panodac.predict(\"panorama.jpg\", model=\"outdoor-swinl\") \"\"\" if model not in AVAILABLE_MODELS : raise ValueError ( f \"Unknown model ' { model } '. Available models: { AVAILABLE_MODELS } \" ) # Get or create cached predictor cache_key = f \" { model } : { device } : { fix_panorama_seam } \" if cache_key not in _predictor_cache : _predictor_cache [ cache_key ] = DepthPredictor ( model = model , device = device , fix_panorama_seam = fix_panorama_seam ) predictor = _predictor_cache [ cache_key ] return predictor ( image ) list_models # list_models () -> list [ str ] List all available pretrained models. Returns: Type Description list [ str ] List of model names that can be passed to predict() Source code in src/panodac/__init__.py 33 34 35 36 37 38 39 def list_models () -> list [ str ]: \"\"\"List all available pretrained models. Returns: List of model names that can be passed to predict() \"\"\" return AVAILABLE_MODELS . copy () get_device # get_device ( device : Union [ str , None ] = None ) -> torch . device Get the best available device for inference. Parameters: Name Type Description Default device Union [ str , None] Specific device to use ('cuda', 'mps', 'cpu'), or None for auto-detection. None Returns: Type Description device torch.device for inference Source code in src/panodac/utils.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 def get_device ( device : Union [ str , None ] = None ) -> torch . device : \"\"\"Get the best available device for inference. Args: device: Specific device to use ('cuda', 'mps', 'cpu'), or None for auto-detection. Returns: torch.device for inference \"\"\" if device is not None : return torch . device ( device ) # Auto-detect best device if torch . backends . mps . is_available (): return torch . device ( \"mps\" ) elif torch . cuda . is_available (): return torch . device ( \"cuda\" ) return torch . device ( \"cpu\" ) Panorama Seam Correction # Panoramic (ERP) depth outputs can show a visible seam at the left/right boundary. panodac applies a Poisson-based seam correction by default when a panorama is detected. You can also call the seam blender directly. fix_panorama_seam # fix_panorama_seam ( depth : ndarray , blend_width : int | None = None , * , anchor_strength : float = 0.001 ) -> np . ndarray Convenience wrapper to fix ERP panorama depth seam artifacts. Parameters: Name Type Description Default depth ndarray (H, W) depth map. required blend_width int | None Half-width of the solve band. If None, auto-pick from width. None Source code in src/panodac/seam_blending.py 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 def fix_panorama_seam ( depth : np . ndarray , blend_width : int | None = None , * , anchor_strength : float = 1e-3 , ) -> np . ndarray : \"\"\" Convenience wrapper to fix ERP panorama depth seam artifacts. Args: depth: (H, W) depth map. blend_width: Half-width of the solve band. If None, auto-pick from width. \"\"\" depth_f = _as_float32_depth ( depth ) H , W = depth_f . shape bw = _recommended_blend_width ( W ) if blend_width is None else int ( blend_width ) blender = PoissonSeamBlender ( blend_width = bw , anchor_strength = float ( anchor_strength )) return blender . blend ( depth_f ) Module Structure # panodac/ \u251c\u2500\u2500 __init__.py # Top-level API (predict, list_models, get_device) \u251c\u2500\u2500 predictor.py # DepthPredictor class \u251c\u2500\u2500 seam_blending.py # Poisson seam correction for ERP panoramas \u251c\u2500\u2500 hub.py # HuggingFace model download \u251c\u2500\u2500 utils.py # Device detection, image loading \u2514\u2500\u2500 models/ # Neural network architectures \u251c\u2500\u2500 idisc.py # IDisc model (perspective) \u251c\u2500\u2500 idisc_erp.py # IDiscERP model (panorama) \u251c\u2500\u2500 encoder.py # Image encoder \u2514\u2500\u2500 backbones/ # ResNet, Swin Transformer Submodules # Predictor - DepthPredictor class for advanced usage Seam Blending - Poisson seam correction utilities Hub - Model download utilities","title":"Overview"},{"location":"api/#api-reference","text":"","title":"API Reference"},{"location":"api/#top-level-api","text":"The main entry points are in the panodac module.","title":"Top-Level API"},{"location":"api/#panodac.predict","text":"predict ( image : Union [ str , Path , ndarray , Image ], model : str = 'outdoor-resnet101' , device : Union [ str , None ] = None , fix_panorama_seam : bool = True ) -> np . ndarray Predict metric depth from any camera image. Supports perspective, fisheye, and 360\u00b0 panorama images. Models are automatically downloaded from HuggingFace on first use. Parameters: Name Type Description Default image Union [ str , Path , ndarray , Image ] Input image. Can be: - Path to image file (str or Path) - numpy array (H, W, 3) in RGB format, values 0-255 - PIL Image required model str Model to use. One of: - 'outdoor-resnet101' (default): Fast outdoor model - 'outdoor-swinl': High-quality outdoor model - 'indoor-resnet101': Fast indoor model - 'indoor-swinl': High-quality indoor model 'outdoor-resnet101' device Union [ str , None] Device to use ('cuda', 'mps', 'cpu', or None for auto-detect) None fix_panorama_seam bool If True (default), apply Poisson blending to correct left-right seam artifacts in ERP panorama depth outputs. True Returns: Type Description ndarray Depth map as numpy array (H, W) with metric depth in meters. Example import panodac depth = panodac.predict(\"photo.jpg\") depth = panodac.predict(\"panorama.jpg\", model=\"outdoor-swinl\") Source code in src/panodac/__init__.py 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 def predict ( image : Union [ str , Path , np . ndarray , Image . Image ], model : str = \"outdoor-resnet101\" , device : Union [ str , None ] = None , fix_panorama_seam : bool = True , ) -> np . ndarray : \"\"\"Predict metric depth from any camera image. Supports perspective, fisheye, and 360\u00b0 panorama images. Models are automatically downloaded from HuggingFace on first use. Args: image: Input image. Can be: - Path to image file (str or Path) - numpy array (H, W, 3) in RGB format, values 0-255 - PIL Image model: Model to use. One of: - 'outdoor-resnet101' (default): Fast outdoor model - 'outdoor-swinl': High-quality outdoor model - 'indoor-resnet101': Fast indoor model - 'indoor-swinl': High-quality indoor model device: Device to use ('cuda', 'mps', 'cpu', or None for auto-detect) fix_panorama_seam: If True (default), apply Poisson blending to correct left-right seam artifacts in ERP panorama depth outputs. Returns: Depth map as numpy array (H, W) with metric depth in meters. Example: >>> import panodac >>> depth = panodac.predict(\"photo.jpg\") >>> depth = panodac.predict(\"panorama.jpg\", model=\"outdoor-swinl\") \"\"\" if model not in AVAILABLE_MODELS : raise ValueError ( f \"Unknown model ' { model } '. Available models: { AVAILABLE_MODELS } \" ) # Get or create cached predictor cache_key = f \" { model } : { device } : { fix_panorama_seam } \" if cache_key not in _predictor_cache : _predictor_cache [ cache_key ] = DepthPredictor ( model = model , device = device , fix_panorama_seam = fix_panorama_seam ) predictor = _predictor_cache [ cache_key ] return predictor ( image )","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-function\"></code>&nbsp;predict"},{"location":"api/#panodac.list_models","text":"list_models () -> list [ str ] List all available pretrained models. Returns: Type Description list [ str ] List of model names that can be passed to predict() Source code in src/panodac/__init__.py 33 34 35 36 37 38 39 def list_models () -> list [ str ]: \"\"\"List all available pretrained models. Returns: List of model names that can be passed to predict() \"\"\" return AVAILABLE_MODELS . copy ()","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-function\"></code>&nbsp;list_models"},{"location":"api/#panodac.get_device","text":"get_device ( device : Union [ str , None ] = None ) -> torch . device Get the best available device for inference. Parameters: Name Type Description Default device Union [ str , None] Specific device to use ('cuda', 'mps', 'cpu'), or None for auto-detection. None Returns: Type Description device torch.device for inference Source code in src/panodac/utils.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 def get_device ( device : Union [ str , None ] = None ) -> torch . device : \"\"\"Get the best available device for inference. Args: device: Specific device to use ('cuda', 'mps', 'cpu'), or None for auto-detection. Returns: torch.device for inference \"\"\" if device is not None : return torch . device ( device ) # Auto-detect best device if torch . backends . mps . is_available (): return torch . device ( \"mps\" ) elif torch . cuda . is_available (): return torch . device ( \"cuda\" ) return torch . device ( \"cpu\" )","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-function\"></code>&nbsp;get_device"},{"location":"api/#panorama-seam-correction","text":"Panoramic (ERP) depth outputs can show a visible seam at the left/right boundary. panodac applies a Poisson-based seam correction by default when a panorama is detected. You can also call the seam blender directly.","title":"Panorama Seam Correction"},{"location":"api/#panodac.seam_blending.fix_panorama_seam","text":"fix_panorama_seam ( depth : ndarray , blend_width : int | None = None , * , anchor_strength : float = 0.001 ) -> np . ndarray Convenience wrapper to fix ERP panorama depth seam artifacts. Parameters: Name Type Description Default depth ndarray (H, W) depth map. required blend_width int | None Half-width of the solve band. If None, auto-pick from width. None Source code in src/panodac/seam_blending.py 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 def fix_panorama_seam ( depth : np . ndarray , blend_width : int | None = None , * , anchor_strength : float = 1e-3 , ) -> np . ndarray : \"\"\" Convenience wrapper to fix ERP panorama depth seam artifacts. Args: depth: (H, W) depth map. blend_width: Half-width of the solve band. If None, auto-pick from width. \"\"\" depth_f = _as_float32_depth ( depth ) H , W = depth_f . shape bw = _recommended_blend_width ( W ) if blend_width is None else int ( blend_width ) blender = PoissonSeamBlender ( blend_width = bw , anchor_strength = float ( anchor_strength )) return blender . blend ( depth_f )","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-function\"></code>&nbsp;fix_panorama_seam"},{"location":"api/#module-structure","text":"panodac/ \u251c\u2500\u2500 __init__.py # Top-level API (predict, list_models, get_device) \u251c\u2500\u2500 predictor.py # DepthPredictor class \u251c\u2500\u2500 seam_blending.py # Poisson seam correction for ERP panoramas \u251c\u2500\u2500 hub.py # HuggingFace model download \u251c\u2500\u2500 utils.py # Device detection, image loading \u2514\u2500\u2500 models/ # Neural network architectures \u251c\u2500\u2500 idisc.py # IDisc model (perspective) \u251c\u2500\u2500 idisc_erp.py # IDiscERP model (panorama) \u251c\u2500\u2500 encoder.py # Image encoder \u2514\u2500\u2500 backbones/ # ResNet, Swin Transformer","title":"Module Structure"},{"location":"api/#submodules","text":"Predictor - DepthPredictor class for advanced usage Seam Blending - Poisson seam correction utilities Hub - Model download utilities","title":"Submodules"},{"location":"api/hub/","text":"Hub # Utilities for downloading models from HuggingFace Hub. Models are cached locally after first download (~500MB each). download_model # download_model # download_model ( name : str ) -> Tuple [ Path , Path ] Download model config and weights from HuggingFace. Files are cached locally after first download. Parameters: Name Type Description Default name str Model name (e.g., 'outdoor-resnet101') required Returns: Type Description Tuple [ Path , Path ] Tuple of (config_path, weights_path) Raises: Type Description ValueError If model name is not recognized Source code in src/panodac/hub.py 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 def download_model ( name : str ) -> Tuple [ Path , Path ]: \"\"\"Download model config and weights from HuggingFace. Files are cached locally after first download. Args: name: Model name (e.g., 'outdoor-resnet101') Returns: Tuple of (config_path, weights_path) Raises: ValueError: If model name is not recognized \"\"\" if name not in MODELS : raise ValueError ( f \"Unknown model ' { name } '. Available: { list ( MODELS . keys ()) } \" ) model_info = MODELS [ name ] config_path = hf_hub_download ( repo_id = HF_REPO , filename = model_info [ \"config\" ], ) weights_path = hf_hub_download ( repo_id = HF_REPO , filename = model_info [ \"weights\" ], ) return Path ( config_path ), Path ( weights_path ) load_config # load_config # load_config ( config_path : Path ) -> dict Load model configuration from JSON file. Parameters: Name Type Description Default config_path Path Path to config JSON file required Returns: Type Description dict Configuration dictionary Source code in src/panodac/hub.py 64 65 66 67 68 69 70 71 72 73 74 def load_config ( config_path : Path ) -> dict : \"\"\"Load model configuration from JSON file. Args: config_path: Path to config JSON file Returns: Configuration dictionary \"\"\" with open ( config_path , \"r\" ) as f : return json . load ( f ) Available Models # Models are hosted at huggingface.co/yuliangguo/depth-any-camera . Model Config File Weights File outdoor-resnet101 dac_resnet101_outdoor.json dac_resnet101_outdoor.pt outdoor-swinl dac_swinl_outdoor.json dac_swinl_outdoor.pt indoor-resnet101 dac_resnet101_indoor.json dac_resnet101_indoor.pt indoor-swinl dac_swinl_indoor.json dac_swinl_indoor.pt","title":"Hub"},{"location":"api/hub/#hub","text":"Utilities for downloading models from HuggingFace Hub. Models are cached locally after first download (~500MB each).","title":"Hub"},{"location":"api/hub/#download_model","text":"","title":"download_model"},{"location":"api/hub/#panodac.hub.download_model","text":"download_model ( name : str ) -> Tuple [ Path , Path ] Download model config and weights from HuggingFace. Files are cached locally after first download. Parameters: Name Type Description Default name str Model name (e.g., 'outdoor-resnet101') required Returns: Type Description Tuple [ Path , Path ] Tuple of (config_path, weights_path) Raises: Type Description ValueError If model name is not recognized Source code in src/panodac/hub.py 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 def download_model ( name : str ) -> Tuple [ Path , Path ]: \"\"\"Download model config and weights from HuggingFace. Files are cached locally after first download. Args: name: Model name (e.g., 'outdoor-resnet101') Returns: Tuple of (config_path, weights_path) Raises: ValueError: If model name is not recognized \"\"\" if name not in MODELS : raise ValueError ( f \"Unknown model ' { name } '. Available: { list ( MODELS . keys ()) } \" ) model_info = MODELS [ name ] config_path = hf_hub_download ( repo_id = HF_REPO , filename = model_info [ \"config\" ], ) weights_path = hf_hub_download ( repo_id = HF_REPO , filename = model_info [ \"weights\" ], ) return Path ( config_path ), Path ( weights_path )","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-function\"></code>&nbsp;download_model"},{"location":"api/hub/#load_config","text":"","title":"load_config"},{"location":"api/hub/#panodac.hub.load_config","text":"load_config ( config_path : Path ) -> dict Load model configuration from JSON file. Parameters: Name Type Description Default config_path Path Path to config JSON file required Returns: Type Description dict Configuration dictionary Source code in src/panodac/hub.py 64 65 66 67 68 69 70 71 72 73 74 def load_config ( config_path : Path ) -> dict : \"\"\"Load model configuration from JSON file. Args: config_path: Path to config JSON file Returns: Configuration dictionary \"\"\" with open ( config_path , \"r\" ) as f : return json . load ( f )","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-function\"></code>&nbsp;load_config"},{"location":"api/hub/#available-models","text":"Models are hosted at huggingface.co/yuliangguo/depth-any-camera . Model Config File Weights File outdoor-resnet101 dac_resnet101_outdoor.json dac_resnet101_outdoor.pt outdoor-swinl dac_swinl_outdoor.json dac_swinl_outdoor.pt indoor-resnet101 dac_resnet101_indoor.json dac_resnet101_indoor.pt indoor-swinl dac_swinl_indoor.json dac_swinl_indoor.pt","title":"Available Models"},{"location":"api/predictor/","text":"Predictor # The DepthPredictor class provides fine-grained control over depth prediction. For most use cases, the top-level panodac.predict() function is sufficient. Use DepthPredictor directly when you need to: Reuse a loaded model across multiple predictions Access the underlying PyTorch model Customize preprocessing behavior DepthPredictor # DepthPredictor # DepthPredictor ( model : str = 'outdoor-resnet101' , device : Union [ str , None ] = None , fix_panorama_seam : bool = True ) High-level interface for depth prediction. Handles model loading, preprocessing, and inference for any camera type. Parameters: Name Type Description Default model str Model name ('outdoor-resnet101', 'outdoor-swinl', etc.) 'outdoor-resnet101' device Union [ str , None] Device to use ('cuda', 'mps', 'cpu', or None for auto) None fix_panorama_seam bool If True, apply Poisson blending to correct left-right seam artifacts in ERP panorama depth outputs. True Source code in src/panodac/predictor.py 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 def __init__ ( self , model : str = \"outdoor-resnet101\" , device : Union [ str , None ] = None , fix_panorama_seam : bool = True , ): self . model_name = model self . device = get_device ( device ) self . fix_panorama_seam = fix_panorama_seam # Download model files config_path , weights_path = download_model ( model ) self . config = load_config ( config_path ) # Build and load model self . _model = self . _build_model () self . _model . load_pretrained ( str ( weights_path )) self . _model . to ( self . device ) self . _model . eval () # Get canonical size from config self . cano_sz = self . config [ \"model\" ] . get ( \"cano_sz\" , [ 1400 , 1400 ]) self . img_size = self . config [ \"model\" ][ \"pixel_encoder\" ][ \"img_size\" ] __call__ # __call__ ( image : Union [ str , Path , ndarray , Image ]) -> np . ndarray Predict depth from an image. Parameters: Name Type Description Default image Union [ str , Path , ndarray , Image ] Input image (path, numpy array, or PIL Image) required Returns: Type Description ndarray Depth map as numpy array (H, W) in meters Source code in src/panodac/predictor.py 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 def __call__ ( self , image : Union [ str , Path , np . ndarray , Image . Image ], ) -> np . ndarray : \"\"\"Predict depth from an image. Args: image: Input image (path, numpy array, or PIL Image) Returns: Depth map as numpy array (H, W) in meters \"\"\" # Load image img_np = load_image ( image ) original_h , original_w = img_np . shape [: 2 ] # Check if panorama and use appropriate processing if is_panorama ( img_np ): return self . _predict_panorama ( img_np ) else : return self . _predict_perspective ( img_np ) Usage # from panodac import DepthPredictor # Create predictor (model loads once) predictor = DepthPredictor ( model = \"outdoor-swinl\" , device = \"cuda\" ) # Reuse for multiple images for image_path in image_paths : depth = predictor ( image_path ) The top-level panodac.predict() function caches predictors internally, so this is mainly useful when you need direct access to the predictor instance.","title":"Predictor"},{"location":"api/predictor/#predictor","text":"The DepthPredictor class provides fine-grained control over depth prediction. For most use cases, the top-level panodac.predict() function is sufficient. Use DepthPredictor directly when you need to: Reuse a loaded model across multiple predictions Access the underlying PyTorch model Customize preprocessing behavior","title":"Predictor"},{"location":"api/predictor/#depthpredictor","text":"","title":"DepthPredictor"},{"location":"api/predictor/#panodac.predictor.DepthPredictor","text":"DepthPredictor ( model : str = 'outdoor-resnet101' , device : Union [ str , None ] = None , fix_panorama_seam : bool = True ) High-level interface for depth prediction. Handles model loading, preprocessing, and inference for any camera type. Parameters: Name Type Description Default model str Model name ('outdoor-resnet101', 'outdoor-swinl', etc.) 'outdoor-resnet101' device Union [ str , None] Device to use ('cuda', 'mps', 'cpu', or None for auto) None fix_panorama_seam bool If True, apply Poisson blending to correct left-right seam artifacts in ERP panorama depth outputs. True Source code in src/panodac/predictor.py 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 def __init__ ( self , model : str = \"outdoor-resnet101\" , device : Union [ str , None ] = None , fix_panorama_seam : bool = True , ): self . model_name = model self . device = get_device ( device ) self . fix_panorama_seam = fix_panorama_seam # Download model files config_path , weights_path = download_model ( model ) self . config = load_config ( config_path ) # Build and load model self . _model = self . _build_model () self . _model . load_pretrained ( str ( weights_path )) self . _model . to ( self . device ) self . _model . eval () # Get canonical size from config self . cano_sz = self . config [ \"model\" ] . get ( \"cano_sz\" , [ 1400 , 1400 ]) self . img_size = self . config [ \"model\" ][ \"pixel_encoder\" ][ \"img_size\" ]","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-class\"></code>&nbsp;DepthPredictor"},{"location":"api/predictor/#panodac.predictor.DepthPredictor.__call__","text":"__call__ ( image : Union [ str , Path , ndarray , Image ]) -> np . ndarray Predict depth from an image. Parameters: Name Type Description Default image Union [ str , Path , ndarray , Image ] Input image (path, numpy array, or PIL Image) required Returns: Type Description ndarray Depth map as numpy array (H, W) in meters Source code in src/panodac/predictor.py 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 def __call__ ( self , image : Union [ str , Path , np . ndarray , Image . Image ], ) -> np . ndarray : \"\"\"Predict depth from an image. Args: image: Input image (path, numpy array, or PIL Image) Returns: Depth map as numpy array (H, W) in meters \"\"\" # Load image img_np = load_image ( image ) original_h , original_w = img_np . shape [: 2 ] # Check if panorama and use appropriate processing if is_panorama ( img_np ): return self . _predict_panorama ( img_np ) else : return self . _predict_perspective ( img_np )","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;__call__"},{"location":"api/predictor/#usage","text":"from panodac import DepthPredictor # Create predictor (model loads once) predictor = DepthPredictor ( model = \"outdoor-swinl\" , device = \"cuda\" ) # Reuse for multiple images for image_path in image_paths : depth = predictor ( image_path ) The top-level panodac.predict() function caches predictors internally, so this is mainly useful when you need direct access to the predictor instance.","title":"Usage"},{"location":"api/seam_blending/","text":"Seam Blending # ERP panoramas wrap horizontally, so the left and right image boundaries are adjacent in 3D . Standard CNN padding can cause a visible seam in predicted depth at that wrap boundary. panodac includes a Poisson-based seam correction that operates in the gradient domain and solves a narrow band around the seam. Usage # Use the built-in panorama seam correction (default) # import panodac # Enabled by default for panoramas depth = panodac . predict ( \"panorama.jpg\" ) # Disable if you want raw output depth_raw = panodac . predict ( \"panorama.jpg\" , fix_panorama_seam = False ) Apply seam correction as a post-process # from panodac.seam_blending import fix_panorama_seam depth_fixed = fix_panorama_seam ( depth_raw , blend_width = 32 ) Tuning: prevent DC/mean drift with anchoring # Poisson blending can drift in absolute scale (DC offset). The seam solver uses a screened Poisson anchoring term controlled by anchor_strength : Higher anchor_strength \u2192 less drift / less change to the original depth in the seam band Lower anchor_strength \u2192 more freedom to match gradients (can improve seam smoothness) from panodac.seam_blending import fix_panorama_seam depth_fixed = fix_panorama_seam ( depth_raw , blend_width = 32 , anchor_strength = 1e-3 , # default ) API # fix_panorama_seam # fix_panorama_seam ( depth : ndarray , blend_width : int | None = None , * , anchor_strength : float = 0.001 ) -> np . ndarray Convenience wrapper to fix ERP panorama depth seam artifacts. Parameters: Name Type Description Default depth ndarray (H, W) depth map. required blend_width int | None Half-width of the solve band. If None, auto-pick from width. None Source code in src/panodac/seam_blending.py 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 def fix_panorama_seam ( depth : np . ndarray , blend_width : int | None = None , * , anchor_strength : float = 1e-3 , ) -> np . ndarray : \"\"\" Convenience wrapper to fix ERP panorama depth seam artifacts. Args: depth: (H, W) depth map. blend_width: Half-width of the solve band. If None, auto-pick from width. \"\"\" depth_f = _as_float32_depth ( depth ) H , W = depth_f . shape bw = _recommended_blend_width ( W ) if blend_width is None else int ( blend_width ) blender = PoissonSeamBlender ( blend_width = bw , anchor_strength = float ( anchor_strength )) return blender . blend ( depth_f ) PoissonSeamBlender dataclass # PoissonSeamBlender ( blend_width : int = 32 , anchor_strength : float = 0.001 , _cached_shape : tuple [ int , int ] | None = None , _cached_A : csr_matrix | None = None ) Poisson blending seam fixer for ERP panoramic depth maps. Parameters: Name Type Description Default blend_width int Half-width (in pixels) of the solve band around the seam after rolling. Total solved band width = 2 * blend_width. 32","title":"Seam Blending"},{"location":"api/seam_blending/#seam-blending","text":"ERP panoramas wrap horizontally, so the left and right image boundaries are adjacent in 3D . Standard CNN padding can cause a visible seam in predicted depth at that wrap boundary. panodac includes a Poisson-based seam correction that operates in the gradient domain and solves a narrow band around the seam.","title":"Seam Blending"},{"location":"api/seam_blending/#usage","text":"","title":"Usage"},{"location":"api/seam_blending/#use-the-built-in-panorama-seam-correction-default","text":"import panodac # Enabled by default for panoramas depth = panodac . predict ( \"panorama.jpg\" ) # Disable if you want raw output depth_raw = panodac . predict ( \"panorama.jpg\" , fix_panorama_seam = False )","title":"Use the built-in panorama seam correction (default)"},{"location":"api/seam_blending/#apply-seam-correction-as-a-post-process","text":"from panodac.seam_blending import fix_panorama_seam depth_fixed = fix_panorama_seam ( depth_raw , blend_width = 32 )","title":"Apply seam correction as a post-process"},{"location":"api/seam_blending/#tuning-prevent-dcmean-drift-with-anchoring","text":"Poisson blending can drift in absolute scale (DC offset). The seam solver uses a screened Poisson anchoring term controlled by anchor_strength : Higher anchor_strength \u2192 less drift / less change to the original depth in the seam band Lower anchor_strength \u2192 more freedom to match gradients (can improve seam smoothness) from panodac.seam_blending import fix_panorama_seam depth_fixed = fix_panorama_seam ( depth_raw , blend_width = 32 , anchor_strength = 1e-3 , # default )","title":"Tuning: prevent DC/mean drift with anchoring"},{"location":"api/seam_blending/#api","text":"","title":"API"},{"location":"api/seam_blending/#panodac.seam_blending.fix_panorama_seam","text":"fix_panorama_seam ( depth : ndarray , blend_width : int | None = None , * , anchor_strength : float = 0.001 ) -> np . ndarray Convenience wrapper to fix ERP panorama depth seam artifacts. Parameters: Name Type Description Default depth ndarray (H, W) depth map. required blend_width int | None Half-width of the solve band. If None, auto-pick from width. None Source code in src/panodac/seam_blending.py 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 def fix_panorama_seam ( depth : np . ndarray , blend_width : int | None = None , * , anchor_strength : float = 1e-3 , ) -> np . ndarray : \"\"\" Convenience wrapper to fix ERP panorama depth seam artifacts. Args: depth: (H, W) depth map. blend_width: Half-width of the solve band. If None, auto-pick from width. \"\"\" depth_f = _as_float32_depth ( depth ) H , W = depth_f . shape bw = _recommended_blend_width ( W ) if blend_width is None else int ( blend_width ) blender = PoissonSeamBlender ( blend_width = bw , anchor_strength = float ( anchor_strength )) return blender . blend ( depth_f )","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-function\"></code>&nbsp;fix_panorama_seam"},{"location":"api/seam_blending/#panodac.seam_blending.PoissonSeamBlender","text":"PoissonSeamBlender ( blend_width : int = 32 , anchor_strength : float = 0.001 , _cached_shape : tuple [ int , int ] | None = None , _cached_A : csr_matrix | None = None ) Poisson blending seam fixer for ERP panoramic depth maps. Parameters: Name Type Description Default blend_width int Half-width (in pixels) of the solve band around the seam after rolling. Total solved band width = 2 * blend_width. 32","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-class\"></code>&nbsp;PoissonSeamBlender"}]}